# Alert Rules for Prometheus
groups:
  - name: application_alerts
    interval: 10s
    rules:
      # Alert when CPU usage exceeds 70%
      - alert: HighCPUUsage
        expr: app_cpu_usage_percent > 70
        for: 30s
        labels:
          severity: warning
          component: application
        annotations:
          summary: "High CPU usage detected on {{ $labels.instance }}"
          description: "CPU usage is {{ $value }}% which is above the 70% threshold for more than 30 seconds."

      # Alert when application becomes unhealthy
      - alert: ApplicationUnhealthy
        expr: app_health_status == 0
        for: 15s
        labels:
          severity: critical
          component: application
        annotations:
          summary: "Application is unhealthy on {{ $labels.instance }}"
          description: "The application health check is reporting unhealthy status."

      # Alert when application is down (no metrics received)
      - alert: ApplicationDown
        expr: up{job="demo-app"} == 0
        for: 30s
        labels:
          severity: critical
          component: application
        annotations:
          summary: "Application is down on {{ $labels.instance }}"
          description: "The application is not responding to Prometheus scrapes."

      # Alert when memory usage is very high
      - alert: HighMemoryUsage
        expr: app_memory_usage_percent > 80
        for: 1m
        labels:
          severity: warning
          component: application
        annotations:
          summary: "High memory usage detected on {{ $labels.instance }}"
          description: "Memory usage is {{ $value }}% which is above the 80% threshold."

      # Alert when response time is slow
      - alert: SlowResponseTime
        expr: rate(app_request_duration_seconds_sum[1m]) / rate(app_request_duration_seconds_count[1m]) > 1
        for: 2m
        labels:
          severity: warning
          component: application
        annotations:
          summary: "Slow response times detected on {{ $labels.instance }}"
          description: "Average response time is {{ $value }}s which is above 1 second threshold."

  - name: node_alerts
    interval: 15s
    rules:
      # Alert when node exporter is down
      - alert: NodeExporterDown
        expr: up{job="node-exporter"} == 0
        for: 1m
        labels:
          severity: warning
          component: monitoring
        annotations:
          summary: "Node Exporter is down on {{ $labels.instance }}"
          description: "Node Exporter has been down for more than 1 minute."
